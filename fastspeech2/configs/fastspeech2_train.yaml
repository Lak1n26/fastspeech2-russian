defaults:
  - model: fastspeech2
  - writer: cometml
  - datasets: ruslan_features  # Use pre-extracted features
  - dataloader: tts_features
  - metrics: null  # Optional: metrics configuration
  - _self_

# Optimizer
optimizer:
  _target_: torch.optim.AdamW
  lr: 1e-4
  betas: [0.9, 0.98]
  eps: 1e-9
  weight_decay: 1e-6

# Learning rate scheduler
lr_scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: 5e-4
  pct_start: 0.1
  anneal_strategy: cos
  total_steps: null  # Will be set by trainer

# Loss function
loss_function:
  _target_: fastspeech2.loss.FastSpeech2LossWrapper
  mel_loss_type: mae  # 'mae' or 'mse'
  lambda_mel: 6.0
  lambda_duration: 1.0
  lambda_pitch: 0.05
  lambda_energy: 0.05

# Metrics for evaluation
metrics:
  train:
    - _target_: fastspeech2.metrics.MelSpectrogramMAE
      name: mel_mae
    - _target_: fastspeech2.metrics.DurationMAE
      name: duration_mae
    - _target_: fastspeech2.metrics.PitchMAE
      name: pitch_mae
    - _target_: fastspeech2.metrics.EnergyMAE
      name: energy_mae

  val:
    - _target_: fastspeech2.metrics.MelSpectrogramMAE
      name: mel_mae
    - _target_: fastspeech2.metrics.MelSpectrogramMSE
      name: mel_mse
    - _target_: fastspeech2.metrics.MelSpectrogramL2Norm
      name: mel_l2
    - _target_: fastspeech2.metrics.DurationAccuracy
      name: duration_accuracy
      tolerance: 5
    - _target_: fastspeech2.metrics.DurationMAE
      name: duration_mae
    - _target_: fastspeech2.metrics.PitchMAE
      name: pitch_mae
    - _target_: fastspeech2.metrics.EnergyMAE
      name: energy_mae

# Trainer settings
trainer:
  n_epochs: 150
  epoch_len: 162  # Number of batches per epoch
  log_step: 162
  device_tensors: ["text_tokens", "mel", "duration", "pitch", "energy"]
  resume_from: null  # null or path to checkpoint
  device: auto  # "cpu", "cuda", or "auto"
  override: false
  monitor: "min val_loss"  # Monitor validation loss
  save_period: 1  # Save checkpoint every N epochs
  early_stop: 150  # NO Early stopping
  save_dir: "saved"
  seed: 42
  grad_clip_thresh: 1.0  # Gradient clipping threshold
  max_grad_norm: 1.0  # Max gradient norm for clipping
  use_amp: false  # Automatic Mixed Precision (set to true for faster GPU training)

# Vocoder configuration (for audio logging)
# To enable audio logging, set enabled: true and provide paths
vocoder:
  enabled: true  # Set to true to enable audio logging
  checkpoint_path: "saved/waveglow/model.ckpt-610000.pt"  # Path to vocoder checkpoint (e.g., "waveglow_256channels_universal_v5.pt")
  params_path: "waveglow_params.json"  # Path to vocoder parameters


# Inference settings
inference:
  duration_control: 1.0  # Speed control (1.0 = normal)
  pitch_control: 1.0     # Pitch control (1.0 = normal)
  energy_control: 1.0    # Energy control (1.0 = normal)
